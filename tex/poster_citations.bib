% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Bono_2017,
  Title                    = {{Modeling somatic and dendritic spike mediated plasticity at the single neuron and network level}},
  Author                   = {Bono, J. and Clopath, C.},
  Journal                  = {nature communications},
  Year                     = {2017},

  Owner                    = {fschubert},
  Timestamp                = {2018.04.17}
}

@Article{Echeveste_2015,
  Title                    = {{The fisher information as a neural guiding principle for independent component analysis}},
  Author                   = {Echeveste, Rodrigo and Eckmann, Samuel and Gros, Claudius},
  Journal                  = {Entropy},
  Year                     = {2015},
  Number                   = {6},
  Pages                    = {3838-3856},
  Volume                   = {17},

  Owner                    = {fschubert},
  Timestamp                = {2018.07.16}
}

@InProceedings{Jaeger_2010,
  Title                    = {{The ``echo state” approach to analysing and training recurrent neural networks – with an Erratum note}},
  Author                   = {Herbert Jaeger},
  Year                     = {2010}
}

@Article{Letzkus_2006,
  Title                    = {{Learning Rules for Spike Timing-Dependent Plasticity Depend on Dendritic Synapse Location}},
  Author                   = {Letzkus, Johannes J. and Kampa, Bj{\"o}rn M. and Stuart, Greg J.},
  Journal                  = {Journal of Neuroscience},
  Year                     = {2006},
  Number                   = {41},
  Pages                    = {10420--10429},
  Volume                   = {26},

  Abstract                 = {Previous studies focusing on the temporal rules governing changes in synaptic strength during spike timing-dependent synaptic plasticity (STDP) have paid little attention to the fact that synaptic inputs are distributed across complex dendritic trees. During STDP, propagation of action potentials (APs) back to the site of synaptic input is thought to trigger plasticity. However, in pyramidal neurons, backpropagation of single APs is decremental, whereas high-frequency bursts lead to generation of distal dendritic calcium spikes. This raises the question whether STDP learning rules depend on synapse location and firing mode. Here, we investigate this issue at synapses between layer 2/3 and layer 5 pyramidal neurons in somatosensory cortex. We find that low-frequency pairing of single APs at positive times leads to a distance-dependent shift to long-term depression (LTD) at distal inputs. At proximal sites, this LTD could be converted to long-term potentiation (LTP) by dendritic depolarizations suprathreshold for BAC-firing or by high-frequency AP bursts. During AP bursts, we observed a progressive, distance-dependent shift in the timing requirements for induction of LTP and LTD, such that distal synapses display novel timing rules: they potentiate when inputs are activated after burst onset (negative timing) but depress when activated before burst onset (positive timing). These findings could be explained by distance-dependent differences in the underlying dendritic voltage waveforms driving NMDA receptor activation during STDP induction. Our results suggest that synapse location within the dendritic tree is a crucial determinant of STDP, and that synapses undergo plasticity according to local rather than global learning rules.},
  Doi                      = {10.1523/JNEUROSCI.2650-06.2006},
  Eprint                   = {http://www.jneurosci.org/content/26/41/10420.full.pdf},
  ISSN                     = {0270-6474},
  Publisher                = {Society for Neuroscience},
  Url                      = {http://www.jneurosci.org/content/26/41/10420}
}

@Article{Lukosevicius_2009,
  Title                    = {{Reservoir computing approaches to recurrent neural network training}},
  Author                   = {Mantas Lukoševičius and Herbert Jaeger},
  Journal                  = {Computer Science Review},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {127 - 149},
  Volume                   = {3},

  Abstract                 = {Echo State Networks and Liquid State Machines introduced a new paradigm in artificial recurrent neural network (RNN) training, where an RNN (the reservoir) is generated randomly and only a readout is trained. The paradigm, becoming known as reservoir computing, greatly facilitated the practical application of RNNs and outperformed classical fully trained RNNs in many tasks. It has lately become a vivid research field with numerous extensions of the basic idea, including reservoir adaptation, thus broadening the initial paradigm to using different methods for training the reservoir and the readout. This review systematically surveys both current ways of generating/adapting the reservoirs and training different types of readouts. It offers a natural conceptual classification of the techniques, which transcends boundaries of the current “brand-names” of reservoir methods, and thus aims to help in unifying the field and providing the reader with a detailed “map” of it.},
  Doi                      = {https://doi.org/10.1016/j.cosrev.2009.03.005},
  ISSN                     = {1574-0137},
  Owner                    = {fschubert},
  Timestamp                = {2018.07.20},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1574013709000173}
}

@Article{Shai_2015,
  Title                    = {{Physiology of Layer 5 Pyramidal Neurons in Mouse Primary Visual Cortex: Coincidence Detection through Bursting}},
  Author                   = {Shai, Adam S. AND Anastassiou, Costas A. AND Larkum, Matthew E. AND Koch, Christof},
  Journal                  = {PLOS Computational Biology},
  Year                     = {2015},

  Month                    = {03},
  Number                   = {3},
  Pages                    = {1-18},
  Volume                   = {11},

  Abstract                 = {Author Summary Neurons in the brain have elaborate dendritic morphologies, hosting a variety of nonlinear channels that give way to single cell computation. In this study, we perform patch clamp recordings in the apical dendrites to establish the spatial distribution of nonlinear channels and the signals they support in the dendrites of layer 5 pyramidal neurons of the mouse primary visual cortex. Using this data, we create a detailed single cell model and simulate synaptic input. We then summarize the results of the simulations using a simple abstracted model, that ultimately describes the computation layer 5 pyramidal neurons perform on synaptic input. We find that this computation is a form of nonlinear frequency-modulation that works in a dendritic-spike dependent manner. Finally, we show how this computation allows dendritic spikes to contribute to the orientation tuning of pyramidal neurons in the visual cortex.},
  Doi                      = {10.1371/journal.pcbi.1004090},
  Publisher                = {Public Library of Science},
  Url                      = {https://doi.org/10.1371/journal.pcbi.1004090}
}

